---
title: A Copy
author: [Alvaro Gaona]
topic: Deep Learning
featuredImage: ../images/lstm-with-tensorflow.jpg
verticalFeaturedImage: ../images/20H-DTC-GiftGuide-GiftsForHer02-SecondaryFeatureRight-Port-2x.jpg
---

# Heading 1

## Heading 2

### Heading 3

#### Heading 4

| A | B | C |
|---|---|---|
| a | b | c |

This tutorial demonstrates how to generate text using a character-based RNN. We will work with a dataset of Shakespeare's writing from Andrej Karpathy's The Unreasonable Effectiveness of Recurrent Neural Networks. Given a sequence of characters from this data ("Shakespear"), train a model to predict the next character in the sequence ("e"). Longer sequences of text can be generated by calling the model repeatedly.

Here's our logo (hover to see the title text):

Inline-style: 
![alt text](https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png "Logo Title Text 1")

Reference-style: 
![alt text][logo]

[logo]: https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png "Logo Title Text 2"

<iframe width="560" height="315" src="https://www.youtube.com/embed/videoseries?list=PLx0sYbCqOb8TBPRdmBHs5Iftvv9TPboYG" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>